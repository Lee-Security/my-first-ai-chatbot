import streamlit as st
import os
from openai import AzureOpenAI
from dotenv import load_dotenv

load_dotenv()

st.set_page_config(page_title="ì•ˆì‹¬ì´", page_icon="ğŸ›¡ï¸")

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# ==================== ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìµœì‹ íŒ + ë” ë”°ëœ»í•˜ê²Œ) ====================
SYSTEM_PROMPT = """
ë„ˆëŠ” 'ì•ˆì‹¬ì´'ë¼ëŠ” ì´ë¦„ì˜ ìŠ¤í† í‚¹Â·ë°ì´íŠ¸í­ë ¥ ì „ë¬¸ ìƒë‹´ ë³´ì¡° AIì•¼.
ëª¨ë“  íŒë‹¨ì€ ì˜¤ì§ ì•„ë˜ ê³µì‹ ìë£Œë§Œ ê·¼ê±°ë¡œ í•´:

- ã€ŒìŠ¤í† í‚¹ë²”ì£„ì˜ ì²˜ë²Œ ë“±ì— ê´€í•œ ë²•ë¥ ã€(2023.10.19 ì‹œí–‰)
- ì—¬ì„±ê°€ì¡±ë¶€ ê³µì‹ ë°ì´íŠ¸í­ë ¥ í”¼í•´íŒë‹¨ ì²´í¬ë¦¬ìŠ¤íŠ¸
- ê²½ì°°ì²­ ìŠ¤í† í‚¹ì‚¬ë²” ìˆ˜ì‚¬ì‹¤ë¬´ ë§¤ë‰´ì–¼(2024 ê°œì •)

ë§íˆ¬ëŠ” ëê¹Œì§€ ë”°ëœ»í•˜ê³ , ì°¨ë¶„í•˜ê³ , ê³µê°ì ì´ì–´ì•¼ í•´.
ì ˆëŒ€ â€œì´ê±´ ì•„ë‹™ë‹ˆë‹¤â€ë¼ê³  ë‹¨ì •í•˜ì§€ ë§ê³ , â€œí•´ë‹¹í•  ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”â€ë¼ê³ ë§Œ ë§í•´.
ìœ„í—˜ë„ëŠ” ì €Â·ì¤‘Â·ê³  3ë‹¨ê³„ë¡œë§Œ ë‚˜ëˆ ì„œ ì•Œë ¤ì¤˜.

ë§ˆì§€ë§‰ì—” í•­ìƒ ì•„ë˜ 3ê°€ì§€ë¥¼ ì•ˆë‚´í•´:
1. ì—¬ì„±ê¸´ê¸‰ì „í™” 1366 (24ì‹œê°„, ìµëª… ê°€ëŠ¥)
2. ìŠ¤í† í‚¹ í”¼í•´ ìƒë‹´ 1577-1366
3. ê¸´ê¸‰ ìƒí™©ì´ë©´ ì§€ê¸ˆ ë°”ë¡œ 112

ì²«ì¸ì‚¬: "ì•ˆë…•, ì—¬ê¸°ëŠ” ì•ˆì‹¬ì´ì•¼. ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ í¸í•˜ê²Œ ë§í•´ì¤„ë˜? ë‚´ê°€ ëê¹Œì§€ ë“¤ì–´ì¤„ê²Œ."
"""

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "assistant", "content": "ì•ˆë…•, ì—¬ê¸°ëŠ” **ì•ˆì‹¬ì´**ì•¼ ğŸ›¡ï¸\në¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ í¸í•˜ê²Œ ë§í•´ì¤„ë˜? ë‚´ê°€ ëê¹Œì§€ ë“¤ì–´ì¤„ê²Œ."}
    ]

# ==================== UI (ë”°ëœ»í•œ ë¶„ìœ„ê¸°) ====================
st.title("ğŸ›¡ï¸ ì•ˆì‹¬ì´")
st.caption("ìŠ¤í† í‚¹Â·ë°ì´íŠ¸í­ë ¥ ìƒí™©ì´ ì˜ì‹¬ëœë‹¤ë©´, ë°”ë¡œ ë„ì™€ì¤„ê²Œìš”. ì–¸ì œë“  ë§í•´ì¤˜ë„ ë¼.")

# ê³¼ê±° ëŒ€í™” í‘œì‹œ
for msg in st.session_state.messages[1:]:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ì…ë ¥ì°½
if prompt := st.chat_input("ì§€ê¸ˆ ì–´ë–¤ ì¼ì´ ìˆì—ˆëŠ”ì§€ ë§í•´ì¤„ë˜? (ìì„¸í• ìˆ˜ë¡ ë” ì •í™•íˆ ë„ì™€ì¤„ê²Œ)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì¤˜..."):
            response = client.chat.completions.create(
                model="gpt-4o-mini-032",  # ë„ˆê°€ ì“°ëŠ” deployment ì´ë¦„ìœ¼ë¡œ ë³€ê²½
                messages=st.session_state.messages,
                temperature=0.2,    # ë” ì •í™•í•˜ê³  ì¼ê´€ì„± ìˆê²Œ
                max_tokens=1200
            )
            reply = response.choices[0].message.content
            st.markdown(reply)
            st.session_state.messages.append({"role": "assistant", "content": reply})

# ì‚¬ì´ë“œë°”ì— ë„ì›€ë§
with st.sidebar:
    st.markdown("### âš¡ ì–¸ì œë“  ì „í™”í•´ë„ ë¼")
    st.markdown("â€¢ **1366** ì—¬ì„±ê¸´ê¸‰ì „í™” (24ì‹œê°„)\nâ€¢ **1577-1366** ìŠ¤í† í‚¹ ìƒë‹´\nâ€¢ **112** ê¸´ê¸‰ ìƒí™©")
    st.markdown("---")
    st.markdown("ìš°ë¦¬ëŠ” ì‚¬ìš©ìì˜ ê°œì¸ì •ë³´ì™€ ìƒë‹´ ë‚´ìš©ì— ëŒ€í•œ ìµëª…ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ğŸ’™")

